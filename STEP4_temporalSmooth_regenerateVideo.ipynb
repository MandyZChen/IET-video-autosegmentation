{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "%matplotlib inline\n",
    "\n",
    "# need to install skimage. on Mac, use the following command\n",
    "# pip install scikit-image\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "import glob\n",
    "from matplotlib import pyplot as plt\n",
    "import skimage.transform\n",
    "import skimage.io\n",
    "import skimage.filters\n",
    "import skimage.util\n",
    "import glob\n",
    "import math\n",
    "from skimage import color\n",
    "from numpy import linalg\n",
    "from PIL import Image\n",
    "from IPython.display import clear_output\n",
    "from skimage.measure import regionprops\n",
    "from skimage import filters\n",
    "from skimage.color import label2rgb\n",
    "import skvideo.io # this could be put on the top of the script\n",
    "\n",
    "# root_folder ='/Users/mandy/Documents/Video_occlusion/'\n",
    "# folder_name = 'Videos/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Remove(duplicate):\n",
    "    final_list = []\n",
    "    for num in duplicate:\n",
    "        if num not in final_list:\n",
    "            final_list.append(num)\n",
    "    return final_list\n",
    "\n",
    "# scale the mask bigger or smaller\n",
    "def zoom(image,center,zoom_factor):\n",
    "    if zoom_factor >= 1:\n",
    "        s_shape = image.shape\n",
    "        image_resized = skimage.transform.rescale(image, zoom_factor, preserve_range = True)\n",
    "        l_shape = image_resized.shape\n",
    "        crop_width = []\n",
    "        up_crop = center[0]*abs(1-zoom_factor)\n",
    "        low_crop = (s_shape[0]-center[0])*abs(1-zoom_factor)\n",
    "        left_crop = center[1]*abs(1-zoom_factor)\n",
    "        right_crop = (s_shape[1]-center[1])*abs(1-zoom_factor)\n",
    "        crop_width.append((up_crop,low_crop))\n",
    "        crop_width.append((left_crop,right_crop))\n",
    "        cropped_image = skimage.util.crop(image_resized, crop_width)\n",
    "    else:\n",
    "        original_shape = image.shape\n",
    "        cropped_image = np.zeros(original_shape)\n",
    "        image_resized = skimage.transform.rescale(image, zoom_factor, preserve_range = True)\n",
    "        up_crop = int(center[0]*abs(1-zoom_factor))\n",
    "        left_crop = int(center[1]*abs(1-zoom_factor))\n",
    "        cropped_image[up_crop:int(up_crop+image_resized.shape[0]),left_crop:int(left_crop+image_resized.shape[1])] = image_resized\n",
    "    return cropped_image\n",
    "\n",
    "# apply gaussian blur to the area where the mask is\n",
    "def applyBlur(image, mask, sigma=50.0, feather=5):\n",
    "    image = skimage.util.img_as_float(image)\n",
    "    image = skimage.transform.resize(image,mask.shape, preserve_range = True)\n",
    "    blurred = skimage.filters.gaussian(image, sigma=sigma, multichannel = True) #skimage.util.img_as_float(mask)*256\n",
    "    blurredmask = skimage.filters.gaussian(skimage.util.img_as_float(mask), sigma=feather, multichannel=True)\n",
    "    blurredmask = np.expand_dims(blurredmask, 2)\n",
    "    inverted_mask =np.ones([blurredmask.shape[0],blurredmask.shape[1],1])-blurredmask\n",
    "    blended = blurredmask*blurred + inverted_mask*image\n",
    "    return blended\n",
    "\n",
    "# apply gaussian blur to the area except the mask\n",
    "def applyBlurContext(image, mask, sigma=50.0, feather=5):\n",
    "    image = skimage.util.img_as_float(image)\n",
    "    image = skimage.transform.resize(image,mask.shape, preserve_range = True)\n",
    "    blurred = skimage.filters.gaussian(image, sigma=sigma, multichannel=True)\n",
    "    blurredmask = skimage.filters.gaussian(skimage.util.img_as_float(mask), sigma=feather, multichannel=True)\n",
    "    blurredmask = np.expand_dims(blurredmask, 2)\n",
    "    inverted_mask =np.ones([blurredmask.shape[0],blurredmask.shape[1],1])- blurredmask\n",
    "    blended = inverted_mask*blurred + blurredmask*image\n",
    "    return blended"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# determine input and output parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "movie_name = 'Forrest_Gump' \n",
    "JPEG_DIR = 'FrameImages' # where to read the frames\n",
    "ANNOTATIONS_DIR = 'Annotations' # where to read the annotated iamges\n",
    "DICTIONARY_DIR = 'DictOutput' # where to read the masks\n",
    "BLURRED_DIR = 'BluredImages' # where to save blurred frames\n",
    "NEWMASKDIR = 'NewMask'# where to read the selected masks\n",
    "CONTEXT_DIR = 'ContextOccluded'\n",
    "\n",
    "outdir = os.path.join(BLURRED_DIR, movie_name)\n",
    "if not os.path.exists(outdir):\n",
    "    os.makedirs(outdir)\n",
    "outdir = os.path.join(NEWMASKDIR, movie_name)\n",
    "if not os.path.exists(outdir):\n",
    "    os.makedirs(outdir)\n",
    "outdir = os.path.join(BLURRED_DIR, movie_name, CONTEXT_DIR)\n",
    "if not os.path.exists(outdir):\n",
    "    os.makedirs(outdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# apply temporal smoothing to make masks look better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_flag = 0\n",
    "frame_list =  sorted(glob.glob(os.path.join(JPEG_DIR, movie_name,'*.jpg')))\n",
    "start_index = 0 # start index of frames to read\n",
    "image_first = plt.imread(frame_list[start_index])\n",
    "original_shape = image_first.shape\n",
    "IOU_THRESHOLD = 0.85 # intersection over union threshold\n",
    "mask_list =  sorted(glob.glob(os.path.join(NEWMASKDIR, movie_name,'*.npz')))\n",
    "Temporal_mean = 15 # avearge with N frames before and N frames after if they satisfy the constraint; the bigger the smoother\n",
    "end_index = len(mask_list) # end index of frames to read\n",
    "\n",
    "zoom_mask_character = 1 # scale the character's mask by this factor; > 1 bigger; <1 smaller\n",
    "zoom_masks_context = 0.85  #scale the context's mask by this factor; > 1 bigger; <1 smaller\n",
    "threshold_value = 0.5\n",
    "\n",
    "for mask_id, mask_path in enumerate(mask_list[start_index:end_index]):\n",
    "    image_path = mask_list[mask_id+start_index]\n",
    "    frame_path = frame_list[mask_id+start_index]\n",
    "    original_frame = plt.imread(frame_path)\n",
    "    mask_npz = np.load(image_path,encoding = 'latin1',fix_imports = True) # get mask\n",
    "    mask_file = mask_npz.files # get the mapping name\n",
    "    new_mask=mask_npz[mask_file[0]] # use the mapping name to retrieve masks\n",
    "    image_name = image_path[-9:-4]\n",
    "    \n",
    "    # determine the masks to average\n",
    "    mask_selected_index = []\n",
    "    mask_num = mask_id + start_index\n",
    "    \n",
    "    # for mask index before the target mask\n",
    "    if mask_num <= Temporal_mean:\n",
    "        for i in np.arange(mask_num):\n",
    "            mask_selected_index.append(i)\n",
    "    else:\n",
    "        for i in np.arange(mask_num-Temporal_mean, mask_num):\n",
    "            mask_selected_index.append(i)\n",
    "        \n",
    "    # for mask index after the target mask\n",
    "    if (mask_num + Temporal_mean) >= end_index:\n",
    "        for i in np.arange(mask_num,end_index):\n",
    "            mask_selected_index.append(i)\n",
    "    else:\n",
    "        for i in np.arange(mask_num, mask_num + Temporal_mean):\n",
    "            mask_selected_index.append(i)\n",
    "    \n",
    "    # see if the mask are all similar\n",
    "    mask_count = 1\n",
    "    mask_to_average = new_mask\n",
    "    for idx in mask_selected_index:\n",
    "        mask_tmp_npz = np.load(mask_list[idx],encoding = 'latin1',fix_imports = True) # get mask\n",
    "        mask_tmp_file = mask_tmp_npz.files # get the mapping name\n",
    "        mask_tmp=mask_tmp_npz[mask_tmp_file[0]] # use the mapping name to retrieve masks\n",
    "        union_area = np.sum((mask_tmp+new_mask)>0) #union area\n",
    "        join_area = np.sum((mask_tmp+new_mask)>1) #union area\n",
    "        if union_area > 0:\n",
    "            if (float(join_area)/float(union_area) > IOU_THRESHOLD):\n",
    "                mask_count = mask_count + 1\n",
    "                mask_to_average = mask_to_average + mask_tmp\n",
    "\n",
    "    averaged_mask = mask_to_average/float(mask_count)\n",
    "    \n",
    "    # get the center of mask\n",
    "#     threshold_value = filters.threshold_otsu(averaged_mask)\n",
    "    labeled_foreground = (averaged_mask > threshold_value).astype(int)\n",
    "    properties = regionprops(labeled_foreground,averaged_mask)\n",
    "    if len(properties)>0:\n",
    "        weighted_center_of_mass = properties[0].weighted_centroid\n",
    "    else:\n",
    "        weighted_center_of_mass = np.round(np.divide(labeled_foreground.shape,2))\n",
    "\n",
    "    ## blur\n",
    "    # substitutded averaged_mask as labeled_foreground here\n",
    "    new_averaged_mask = zoom(labeled_foreground, weighted_center_of_mass, zoom_mask_character)\n",
    "    blurred_frame = applyBlur(original_frame, new_averaged_mask)\n",
    "    blurred_frame = skimage.transform.resize(blurred_frame,(original_shape[0],original_shape[1]), preserve_range = True)\n",
    "    plt.imsave(os.path.join(BLURRED_DIR,movie_name, image_name + '.jpg'), blurred_frame)  \n",
    "\n",
    "    # save context occluded blurred image\n",
    "    new_averaged_mask = zoom(labeled_foreground, weighted_center_of_mass, zoom_masks_context)\n",
    "    blurred_frame_context = applyBlurContext(original_frame, new_averaged_mask)\n",
    "    blurred_frame_context = skimage.transform.resize(blurred_frame_context,(original_shape[0],original_shape[1]), preserve_range = True)\n",
    "    plt.imsave(os.path.join(BLURRED_DIR,movie_name,CONTEXT_DIR, image_name + '.jpg'), blurred_frame_context)  \n",
    "\n",
    "    # report progress\n",
    "    progress = np.divide(np.float32(mask_id+start_index),np.float32(end_index))\n",
    "    if np.remainder(mask_id,20)== 0:\n",
    "        clear_output()\n",
    "        \n",
    "    print('Processing '+ 'image ' + str(mask_id) + '/'+ str(end_index-start_index)+ '. Progress =' + str(progress))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generate new video using the blurred frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# video for occluding the target character\n",
    "fps = '25'\n",
    "start_index = 0\n",
    "blurred_frame_list =  sorted(glob.glob(os.path.join(BLURRED_DIR, movie_name,'*.jpg')))\n",
    "end_index = len(blurred_frame_list)\n",
    "first_frame = plt.imread(blurred_frame_list[0])\n",
    "video_shape = (2,first_frame.shape[0],first_frame.shape[1],first_frame.shape[2])\n",
    "if testing_flag:\n",
    "    output_name = movie_name + '_test.mp4'\n",
    "else:\n",
    "    output_name = movie_name + '.mp4'\n",
    "vid_out = skvideo.io.FFmpegWriter(output_name,\n",
    "    outputdict={\n",
    "      '-vcodec': 'libx264','-pix_fmt': 'yuv420p','-r': fps})\n",
    "blendedvideo = np.zeros(video_shape)\n",
    "for frame in blurred_frame_list[start_index:end_index]:\n",
    "    blurred_image = plt.imread(frame)\n",
    "    blendedvideo[0,:,:,:] = blurred_image\n",
    "    vid_out.writeFrame(blendedvideo[0,:,:,:])        \n",
    "vid_out.close()\n",
    "print('finished generating character-only videos')\n",
    "\n",
    "# video for occluding the context\n",
    "blurred_frame_list =  sorted(glob.glob(os.path.join(BLURRED_DIR, movie_name, CONTEXT_DIR, '*.jpg')))\n",
    "first_frame = plt.imread(blurred_frame_list[0])\n",
    "end_index = len(blurred_frame_list)\n",
    "video_shape = (2,first_frame.shape[0],first_frame.shape[1],first_frame.shape[2])\n",
    "if testing_flag:\n",
    "    output_name = movie_name + 'Context_test.mp4'\n",
    "else:\n",
    "    output_name = movie_name + 'Context.mp4'\n",
    "vid_out = skvideo.io.FFmpegWriter(output_name,\n",
    "    outputdict={\n",
    "      '-vcodec': 'libx264','-pix_fmt': 'yuv420p','-r': fps})\n",
    "blendedvideo = np.zeros(video_shape)\n",
    "for frame in blurred_frame_list[start_index:end_index]:\n",
    "    blurred_image = plt.imread(frame)\n",
    "    blendedvideo[0,:,:,:] = blurred_image\n",
    "    vid_out.writeFrame(blendedvideo[0,:,:,:])        \n",
    "vid_out.close()\n",
    "print('finished generating context-only videos')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
